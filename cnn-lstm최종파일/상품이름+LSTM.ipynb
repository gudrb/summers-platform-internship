{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymssql\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "from pandas import Series,DataFrame\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import urllib.request #이미지 다운로드\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#피클 파일 불러오기 \n",
    "with open('shoda4000.pickle','rb') as fr: \n",
    "    result3 = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#인덱스 섞어주기\n",
    "result3 = pd.concat([result3],ignore_index=True)\n",
    "result3 = result3.reindex(np.random.permutation(result3.index)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#원핫벡터 정답 label 만들어주기\n",
    "from keras.utils.np_utils import to_categorical\n",
    "labels = to_categorical(result3['LABEL'], num_classes =8) \n",
    "print(labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#토크나이징\n",
    "vocabulary_size = 10000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(result3['pl_goodsnm'])\n",
    "\n",
    "sequences= tokenizer.texts_to_sequences(result3['pl_goodsnm'])\n",
    "data = pad_sequences(sequences, maxlen=10)\n",
    "#데이터셋 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "data_train,data_test,labels_train,labels_test = train_test_split(data,labels, test_size = 0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#임벨런스드 데이터 오버 샘플링 - 시간 오래걸림, 성능개선x\n",
    "# from imblearn.over_sampling import SMOTE \n",
    "# sm = SMOTE(random_state=12)\n",
    "# data_train_sm, labels_train_sm = sm.fit_sample(data_train,labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LSTM모델\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 200, input_length=10))\n",
    "model.add(LSTM(10, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(8,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13124 samples, validate on 3281 samples\n",
      "Epoch 1/10\n",
      "13124/13124 [==============================] - 4s 337us/step - loss: 1.6871 - acc: 0.5082 - val_loss: 1.1833 - val_acc: 0.7230\n",
      "Epoch 2/10\n",
      "13124/13124 [==============================] - 4s 269us/step - loss: 0.8659 - acc: 0.7966 - val_loss: 0.7191 - val_acc: 0.8226\n",
      "Epoch 3/10\n",
      "13124/13124 [==============================] - 4s 268us/step - loss: 0.5520 - acc: 0.8667 - val_loss: 0.6375 - val_acc: 0.8333\n",
      "Epoch 4/10\n",
      "13124/13124 [==============================] - 4s 269us/step - loss: 0.4201 - acc: 0.8958 - val_loss: 0.6174 - val_acc: 0.8379\n",
      "Epoch 5/10\n",
      "10300/13124 [======================>.......] - ETA: 0s - loss: 0.3465 - acc: 0.9139"
     ]
    }
   ],
   "source": [
    "#모델 학습\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping()\n",
    "hist = model.fit(data_train,labels_train, epochs=10,batch_size = 100, validation_split = 0.2,callbacks=[early_stopping])\n",
    "keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#성능 측정\n",
    "accr = model.evaluate(data_test,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#학습 그래프\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
